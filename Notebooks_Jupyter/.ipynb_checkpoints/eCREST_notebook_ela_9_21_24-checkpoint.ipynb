{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd548e97-d216-4bf7-b535-b4bd8d8f6c7c",
   "metadata": {},
   "source": [
    "# eCREST_notebook\n",
    "\n",
    "Basic functions for reconstructing cells.\n",
    "\n",
    "# Setup\n",
    "\n",
    "Do the following two setup steps regardless of how you will be using this script. \n",
    "\n",
    "## 1. Imports\n",
    "\n",
    "Run the following code cell to import the necessary packages and modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e0d80baf-52c9-4daf-98eb-9e9ac1eddc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "28175797-a93e-416b-a889-3f68e265fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################ \n",
    "# Get the latest CREST files for each ID within the target folder (dirname)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sqlite3 import connect as sqlite3_connect\n",
    "from sqlite3 import DatabaseError\n",
    "from igraph import Graph as ig_Graph\n",
    "from igraph import plot as ig_plot\n",
    "from scipy.spatial.distance import cdist\n",
    "from random import choice as random_choice\n",
    "from itertools import combinations\n",
    "from numpy import array, unravel_index, argmin, mean,unique,nan\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import neuroglancer\n",
    "from webbrowser import open as wb_open\n",
    "from webbrowser import open_new as wb_open_new\n",
    "import neuroglancer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from eCREST_cli_beta import ecrest, import_settings\n",
    "from eCREST_cli import ecrest, import_settings, get_cell_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d46fbc9f-defa-4e8b-a7f3-9a2704adbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_segments_dict(dirpath):\n",
    "\n",
    "    nodefiles = [child.name for child in sorted(dirpath.iterdir()) if (child.name[0]!='.') & (child.is_file()) & (\"desktop\" not in child.name)]\n",
    "\n",
    "    # Create a base_segments dictionary of all cells in the directory\n",
    "    base_segments = {}\n",
    "    for x in nodefiles:\n",
    "        # print(x)\n",
    "        with open(dirpath / x, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "            cell_data=myfile.read()\n",
    "            cell_data = json.loads(cell_data)\n",
    "        base_segments[x] = set([a for b in cell_data['base_segments'].values() for a in b]) #cell.cell_data['base_segments']\n",
    "        # base_segments[x] = set([a for b in cell_data['base_segments'].values() for a in b]) #cell.cell_data['base_segments']\n",
    "\n",
    "    return base_segments\n",
    "\n",
    "def check_duplicates(base_segments):\n",
    "    '''\n",
    "    base_segments is a dictionary of all segments that this script checks among\n",
    "    '''\n",
    "    df_all = pd.DataFrame()\n",
    "    for _,this_cell in base_segments.items():\n",
    "        overlap = []\n",
    "        num_dup = []\n",
    "        for x in base_segments.keys():\n",
    "            overlap.append(len(this_cell&base_segments[x])/len(base_segments[x]))\n",
    "            num_dup.append(len(this_cell&base_segments[x]))\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"self\": _,\n",
    "            \"dups\": list(base_segments.keys()),\n",
    "            \"overlap-percent\": overlap,\n",
    "            \"number_seg_lap\": num_dup\n",
    "            }).replace(0, nan, inplace=False).dropna()\n",
    "        df = df[df['dups'] != _]\n",
    "        if not df.empty:\n",
    "            df_all = pd.concat([df_all,df]) \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832d693-5b15-4b06-ac7a-8721e1adc7d3",
   "metadata": {},
   "source": [
    "The 'ecrest' class has been imported from eCREST_cli.py\n",
    "\n",
    "An instance of this object will be able to do things like:\n",
    "- open an neuroglancer viewer for proofrieading (see \"Proofread using CREST\")\n",
    "    - add-remove segments (using graph feature for efficiency)\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "- add or remove annotation layers (see \"Annotation Layers\")\n",
    "- check for overlap with other .json files in a directory folder (see \"check for overlap\")\n",
    "- label cell structures\n",
    "- add base_segments from a list (see \"add segments\")\n",
    "- import annotations from another file (see \"Annotation Import\")\n",
    "- convert from neuroglancer json (see \"Convert From Neuroglancer to eCREST\")\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389865b-9c52-4e0d-9261-f94b8ad49784",
   "metadata": {},
   "source": [
    "## 2. Settings definitions\n",
    "\n",
    "Whether you are converting from neuroglancer or creating a new reconstruction, the settings_dict parameters is needed to create CREST json files with correct formatting. \n",
    "- 'save_dir' : the directory where JSON files are saved \n",
    "- 'cred' and 'db_path' : specify the path to the agglomeration database file on your local computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e49e4bd-680e-4d3b-9238-2e658542e1b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path_to_settings_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m settings_dict \u001b[38;5;241m=\u001b[39m import_settings(path_to_settings_json)\n",
      "File \u001b[0;32m~/Documents/Neuroscience with Nate/neuroglancerproject/eCREST/eCREST-main/eCREST_cli.py:1512\u001b[0m, in \u001b[0;36mimport_settings\u001b[0;34m(dict_json)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_settings\u001b[39m(dict_json):\n\u001b[0;32m-> 1512\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dict_json, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m myfile: \u001b[38;5;66;03m# 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m         settings_dict\u001b[38;5;241m=\u001b[39mmyfile\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1514\u001b[0m         settings_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(settings_dict)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'"
     ]
    }
   ],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed2d2c-3972-4525-9832-7006b8fef85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e22556b-95c5-4a47-b48a-01799430bf8a",
   "metadata": {},
   "source": [
    "# Proofread using (e)CREST\n",
    "\n",
    "The ```ecrest``` class defined in eCREST_cli.py can be used to proofread base_segment reconstructions enhanced by the agglomeration database.\n",
    "\n",
    "An instance of this class can be initialized with either:\n",
    "- ecrest(segment_id): a \"main_base_id\" in *int* format\n",
    "- ecrest(filepath): an existing CREST .json file\n",
    "- ecrest(segment_id, segment_list): the main_base_id from the neuroglancer file you are converting and a list of base_segments.\n",
    "\n",
    "The ```launch_viewer``` flag default is \"False\" so that you can interact with the contents of a reconstruction without actually opening it visually in a neuroglancer tab. **NOTE**: Some ecrest functions require that the ecrest instance is created with ```launch_viewer==True```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a9c9ea-4607-4f08-917f-ac0095839a55",
   "metadata": {},
   "source": [
    "## Get base_segments dictionaries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c1b30-1dba-4d4f-848a-06d086477c19",
   "metadata": {},
   "source": [
    "### Read from file (created with [this Colab notebook](https://colab.research.google.com/drive/19N8taRKeTt_Bgx_yF5AD5ntkU7zy7unc?usp=sharing)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342baa6-6f5a-4c1e-82c0-0e12ca5511cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read list of dictionaries from a JSON file\n",
    "with open(Path(settings_dict['save_dir']) /'Rachel/dictionary_jsons/dictionaries.json', 'r') as json_file: #assumes your save_dir is /mg_network/Rachel/ on your working computer\n",
    "    dict_all = json.load(json_file)\n",
    "  \n",
    "dict_list = dict_all.keys()\n",
    "\n",
    "# Convert lists to sets within each dictionary in data\n",
    "for key, dictionary in dict_all.items():\n",
    "    for sub_key, value in dictionary.items():\n",
    "        if isinstance(value, list):\n",
    "            dictionary[sub_key] = set(value)\n",
    "\n",
    "# Dynamically create dictionaries based on the JSON keys\n",
    "for key, value in dict_all.items():\n",
    "    globals()[key] = value\n",
    "\n",
    "print(dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c186673b-660d-4363-88cf-ed7a306403c3",
   "metadata": {},
   "source": [
    "### Create locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb806a-8cb7-41e3-9022-4062f30b1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base segment dictionaries to check for duplicates\n",
    "# use manually-defined function in setup for \"get_base_segments_dict, which can check for files with same id)\"\n",
    "base_segments_net = get_base_segments_dict(Path(settings_dict['save_dir'])) \n",
    "base_segments_todo1 = get_base_segments_dict(Path(settings_dict['save_dir'])/'Rachel') #/'todo/grc_483610898_pre')#\n",
    "base_segments_todo2 = get_base_segments_dict(Path(settings_dict['save_dir'])/'todo/sg2_306461085_pre') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcf9377-3063-45b5-a6eb-eb9fe97f3037",
   "metadata": {},
   "source": [
    "## NEW reconstruction from segment ID\n",
    "\n",
    "If you wanted to start reconstructing a new cell from a main base segment, you would use the following code block to launch.\n",
    "\n",
    "To change the save location you can specify the ```directory_path``` flag in the ```save_cell_graph()``` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde92fb-32e3-4e3a-a2d2-36fb55d63864",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(get_cell_filepaths(Path(settings_dict['save_dir']) / 'todo/sg2_306461085_pre'))# mg2_386426114_pre')) # 'Rachel')) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf641470-0569-403b-b35d-ebaa96ce4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = '132341930'#     \n",
    "crest = ecrest(settings_dict,segment_id = segment_id, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f533a-3d12-4536-887d-da9b6859f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.change_key_binding({\"alt+mousedown0\" : \"add-or-remove-seg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc618dc-2bd9-44d7-ad16-9e4be5dbd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.add_endpoint_annotation_layers(['soma'],link=True) # spine_inputs\n",
    "print(crest.get_ctype('manual'))\n",
    "\n",
    "### check for duplicates in working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d116c25-a7a2-4539-9638-42e9a6343931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'this file is: {cell_filepaths[cell_id].name}')\n",
    "print('')\n",
    "# actually check for duplicates of current reconstruction with base segments dictionary\n",
    "# to save time, this line can be run alone after initializing base_segments dictionary above\n",
    "print('overlap in main network:'); df = crest.check_duplicates(base_segments_net); display(df)\n",
    "print('overlap in Rachel folder:'); df = crest.check_duplicates(base_segments_todo1); display(df)\n",
    "print('overlap in todo folder:'); df = crest.check_duplicates(base_segments_todo2); display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe5da1-caca-4c63-973f-6acbc7921439",
   "metadata": {},
   "source": [
    "### define cell type and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95089176-2759-4080-9158-3ed12036c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = 'fov' # Assign the cell type then run the code cell\n",
    "\n",
    "crest.define_ctype(cell_type,\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927d429-28b6-40e3-92dc-9af06024c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55189cf-a176-47e3-98a0-58def36c26f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## EDIT reconstruction from file\n",
    "\n",
    "If you wanted to edit a reconstruction from an existing file, you would use the following code block to launch.\n",
    "\n",
    "Specify the cell_id and the path to the directory that cell is in. \n",
    "\n",
    "> NOTE: You can also directly copy paste the full filepath to the cell you want to open and pass it to the ```filepath``` flag.  \n",
    "In that case, the only code you need is crest = ecrest(settings_dict,filepath= [*paste filepath here*], launch_viewer=True)\n",
    "\n",
    "To change the save location you can specify the ```directory_path``` flag in the ```save_cell_graph()``` module\n",
    "\n",
    "> To overwrite a file (not recommended), specify ```(directory_path = cell_filepaths[cell_id].parent, file_name = cell_filepaths[cell_id].name)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4326ca-859e-46c8-b34f-092f94f2af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = Path(settings_dict['save_dir'])#/'Rachel' # specify the directory path\n",
    "\n",
    "cell_filepaths = get_cell_filepaths(directory_path) # gets filepaths for all cells in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b5531-acd7-4420-969d-92787cef58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = '132342130' # specify the cell id\n",
    "\n",
    "crest = ecrest(settings_dict,filepath= cell_filepaths[cell_id], launch_viewer=True)\n",
    "# crest = ecrest(settings_dict,filepath= directory_path.parent/ 'cell_graph_221592066__2023-10-12 09.10.56.json', launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f0f7d-8d67-455c-bf48-9e6ac973ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.change_key_binding({\"alt+mousedown0\" : \"add-or-remove-seg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c32b7-7514-4765-bd3a-a5bd42788ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates in working directories\n",
    "\n",
    "print(f'this file is: {cell_filepaths[cell_id].name}')\n",
    "print('')\n",
    "# actually check for duplicates of current reconstruction with base segments dictionary\n",
    "# to save time, this line can be run alone after initializing base_segments dictionary above\n",
    "print('overlap in main network:'); df = crest.check_duplicates(base_segments_net); display(df)\n",
    "print('overlap in Rachel folder:'); df = crest.check_duplicates(base_segments_todo1); display(df)\n",
    "print('overlap in todo folder:'); df = crest.check_duplicates(base_segments_todo2); display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915fc52-b460-4655-9755-c5af48a05525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crest.add_endpoint_annotation_layers(['soma'],link=True) # spine_inputs\n",
    "print(crest.get_ctype('manual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a924f54-44b4-4b16-83ed-77de1c24a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.add_endpoint_annotation_layers(['soma'],link=True) # spine_inputs\n",
    "print(crest.get_ctype('manual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9ea-2dd1-4c52-a81c-cdf1337ff1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE YOUR WORK!\n",
    "\n",
    "crest.save_cell_graph() # Default location is Path(settings_dict['save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7206f227-a18e-40b2-8ed7-9163719d8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## do not use unless certain - this overwrites the original file rather than making a new one\n",
    "# crest.save_cell_graph(directory_path = cell_filepaths[cell_id].parent, file_name = cell_filepaths[cell_id].name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e634655-2318-4eee-85e4-a972c0eac064",
   "metadata": {},
   "source": [
    "## Define Cell type\n",
    "\n",
    "The cell type strings to use are:  \n",
    "aff, grc-d, grc-s, sgx1, sgx2, sg1, sg2, mg1, mg2, lf, lg, uk, fov\n",
    "\n",
    "You can also check the current cell type assigned by using ```crest.get_ctype(\"manual\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96728c2f-cc5c-4427-8e10-66708ff172f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = 'grc' # Assign the cell type then run the code cell\n",
    "\n",
    "crest.define_ctype(cell_type,\"manual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd72f91-fd9d-4e55-ada6-2f1b81e124d1",
   "metadata": {},
   "source": [
    "## Change Function Keybindings\n",
    "\n",
    "speficy any keybindings that you want in ```keybindings_dict``` and pass that to the class module ```change_key_binding```. The keybinding mapping will be returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b913f-79ad-4cad-b181-d9116dbfe7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keybindings_dict = {\n",
    "    \"alt+mousedown0\" : \"add-or-remove-seg\"\n",
    "}\n",
    "\n",
    "crest.change_key_binding(keybindings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a5f6a5-ba38-419c-89f2-67839cf3cf05",
   "metadata": {},
   "source": [
    "## Check for overlap with other .json files in a directory\n",
    "\n",
    "Use the ecrest module ```get_base_segments_dict``` to get a dictionary of {'cell_id' : 'base_segments'} for all .json files in a folder.  \n",
    "Then use the ecrest module ```check_duplicates``` to get a dataframe of any instances of overlap between that cell and the .json files from the folder.\n",
    "\n",
    "*Tips*:\n",
    "- You do ***not*** need to run ```get_base_segments_dict``` every time. For each new crest instance you create, you can just skip to the ```check_duplicates``` step.\n",
    "- You can create multiple dictionaries to check against... you can create a separate line of code for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18266060-8c3d-45f8-8e0c-606dcca45d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_segments_net = get_base_segments_dict(Path(settings_dict['save_dir']))\n",
    "base_segments_todo = get_base_segments_dict(Path(settings_dict['save_dir']) / 'kp/392042360_grc-s_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276834c-034f-4723-a0c3-3ccc34888e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('overlap in main network:'); df = crest.check_duplicates(base_segments_net); display(df)\n",
    "print('overlap in todo folder:'); df = crest.check_duplicates(base_segments_todo); display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e195932-6784-4259-8012-b44f447dc5dd",
   "metadata": {},
   "source": [
    "## Add/Remove Annotation layers\n",
    "\n",
    "Because of how CREST saves the .json state, annotation layers need to be added/removed programatically rather than via the neuroglancer viewer directly.\n",
    "\n",
    "Comment/uncomment the following two module implementations as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5625ae-aa2e-4925-904a-b1403bbd7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.add_endpoint_annotation_layers(['skeleton'])\n",
    "\n",
    "# crest.del_endpoint_annotation_layers(['soma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03c66d-b78d-49fd-a8e7-e8fdecb2fd79",
   "metadata": {},
   "source": [
    "## spine density annotation functions\n",
    "\n",
    "If you want to be able to move annotations, don't change alt+mouse0 keybinding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4e062-0486-4eb9-9260-f500a29279b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.add_endpoint_annotation_layers(['volume'],link=False) # spine_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb655dad-80c7-44fa-9626-e42dd010e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 5000 # distance along dendrite in nm\n",
    "\n",
    "crest.add_endpoint_annotation('spineD loc',to_vox=False, center = [17497, 6482, 2001], radii = [l/16,l/16,l/30]) # 'center' is in middle of dendrite in voxels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece8af1-1542-4582-bbee-ee3855084eed",
   "metadata": {},
   "source": [
    "## SAVE YOUR WORK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82beafa5-733d-415f-a9b4-f23d8f7d1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.save_cell_graph() # Default location is Path(settings_dict['save_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4acea1-cb12-4d27-b988-f17071919886",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912430b3-af66-4d25-b2cc-cf70bb445d19",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## search for synapse by segment annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5fb8c6-5a69-4574-a44f-f4296bbea676",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = Path(settings_dict['save_dir']) #/ 'kp/pfs'#/ 'volume-subsample-all/in_progress'  ## specify the directory path\n",
    "cell_filepaths = get_cell_filepaths(directory_path) # gets filepaths for all cells in a directory\n",
    "# cell_filepaths = cell_filepaths_mainnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2662ec5-5cde-4b86-989f-5e4a683cef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "         \n",
    "syn_type = 'post-synaptic' #'spine_inputs' #\n",
    "segs_to_find = ['564132646','565215897']\n",
    "cells_todo = list(cell_filepaths.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002033ea-d83d-4c74-8f49-cbce9b2ea333",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx_sizes = [16, 16, 30]\n",
    "\n",
    "for c_id in cells_todo:\n",
    "    crest = ecrest(settings_dict,filepath= cell_filepaths[c_id], launch_viewer=False)\n",
    "    for syn_ in crest.cell_data['end_points'][syn_type]:\n",
    "        try:\n",
    "            if syn_[3] in segs_to_find:\n",
    "                print(f'in cell {c_id}, segment {syn_[3]} is at synapse location {array([int(syn_[i]/vx_sizes[i]) for i in range(3)])}')\n",
    "\n",
    "        except IndexError as msg:\n",
    "            print(msg, f'for cell {c_id} synapse at {array([int(syn_[i]/vx_sizes[i]) for i in range(3)])} has no segment id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c883d-fbfd-4f70-bb22-043da2b3009d",
   "metadata": {},
   "source": [
    "## cell types for all files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba89b1-c92b-4bd0-9538-84b27cecee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodefiles = get_cell_filepaths(Path(settings_dict['save_dir'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f4d5f-3050-4aa3-a46c-d226465e27e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = {}\n",
    "not_typed = []\n",
    "for x,f in nodefiles.items():\n",
    "    cell = ecrest(settings_dict,filepath = f,launch_viewer=False)\n",
    "    cell_type[x] = cell.get_ctype('manual') \n",
    "    if (cell.get_ctype('manual') == []) | (cell.get_ctype('manual') == ''):\n",
    "        cell_type[x]=''\n",
    "        not_typed.append(x)# print(f'cell {x} is not cell-typed in json')\n",
    "        \n",
    "print('the following cells are not typed in the main network')\n",
    "print(not_typed)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60242e93-2010-4d64-a549-f83c7b6bbbed",
   "metadata": {},
   "source": [
    "## if get assertion error and won't save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a8675-d224-4282-a994-22d4b3f54267",
   "metadata": {},
   "outputs": [],
   "source": [
    "seglist = crest.cell_data['base_segments']['unknown']\n",
    "\n",
    "anchor = crest.cell_data['metadata']['main_seg']['base']\n",
    "\n",
    "crest2 = ecrest(settings_dict,segment_id = anchor, segment_list = seglist, launch_viewer=True)\n",
    "\n",
    "# SAVE YOUR WORK!\n",
    "\n",
    "crest2.cell_data['end_points']=crest.cell_data['end_points']\n",
    "\n",
    "\n",
    "crest2.load_annotation_layer_points()\n",
    "\n",
    "crest2.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29afc759-33ae-4796-be14-64cf25d0e6f9",
   "metadata": {},
   "source": [
    "## volume of annotation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a2fc4-b1c9-4c1e-8618-677db2e7610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "# hull_of_df1 = ConvexHull(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b0469d2a-f632-4da3-aebf-c46cb2067012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pf_283546587_335024_134448_19230.json\n",
      "pf_283546587_417488_170480_97200.json\n",
      "pf_369312360_300240_169712_78420.json\n"
     ]
    }
   ],
   "source": [
    "## if this isn't working there might be hidden files blocking the code from working\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "for f in sorted(listdir('/Users/Ela_work/Documents/Neuroscience with Nate/neuroglancerproject/annotatedsynapses_new/')):\n",
    "        if f[0]==\".\":\n",
    "            continue\n",
    "            \n",
    "        print (f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3cccd941-36c3-4209-8496-dcb87810a41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pf_283546452_321472_150080_31470.json 0.2735323553352328 0.7058762720435193\n",
      "pf_283546452_331008_159664_50850.json 0.074629634532604 0.16099522764385116\n",
      "pf_283546452_331932_156306_44475.json 0.07619952764210075 0.23569582415480406\n",
      "pf_283546452_332362_155274_48375.json 0.08473059124334768 0.3770430692496547\n",
      "pf_283546452_355241_165082_53775.json 0.12394640105794488 0.4236697987778179\n",
      "pf_283546452_368864_169712_60210.json 0.031199179578200672 0.27410036484721\n",
      "pf_283546452_398304_169520_78180.json 0.11044217208102573 1.5996337376816907\n",
      "pf_283546452_409536_175088_91170.json 0.09138976300025083 0.27760294979555467\n",
      "pf_283546452_433361_167202_100455.json 0.06628452208873274 0.5877877588982144\n",
      "pf_283546587_331408_143618_43875.json 0.013061511525309395 0.08702666439134893\n",
      "pf_283546587_333152_155680_50160.json 0.10692650821358143 0.8684314120934391\n",
      "pf_283546587_335024_134448_19230.json 0.15025379149688056 1.4738900370795283\n",
      "pf_283546587_337520_160992_60180.json 0.06180995189687651 0.6016206789684747\n",
      "pf_283546587_402288_168528_86730.json 0.09378377577996007 1.3938159725581598\n",
      "pf_283546587_406525_168726_87015.json 0.01752753556952045 0.5124871681634385\n",
      "pf_283546587_417488_170480_97200.json 0.10569492878008913 0.9071580333429853\n",
      "pf_283546587_439798_174648_96885.json 0.03425529800971732 0.17238395976377024\n",
      "pf_283548237_269168_156240_9090.json 0.06905597325736074 0.4037674299864276\n",
      "pf_283548237_272816_155472_13710.json 0.055272861294531773 0.33163036668783435\n",
      "pf_283548237_315712_156592_42150.json 0.08690663219801947 0.43120592900308463\n",
      "pf_283548237_325600_156480_57390.json 0.0731869104519298 0.24075043051743306\n",
      "pf_283548237_332416_155936_51210.json 0.055020910441596176 0.1707835268503492\n",
      "pf_283548237_333056_156432_70500.json 0.04690713186285933 0.03975277194967946\n",
      "pf_283548237_336704_158752_72630.json 0.1326275549510771 0.3583743263873641\n",
      "pf_283548237_354245_153755_69615.json 0.043959441674262315 0.10135558197673569\n",
      "pf_283548237_379680_140352_57060.json 0.05210959349397897 0.17194836898967228\n",
      "pf_283548237_394494_141434_53265.json 0.021661226688650743 0.28588428931441606\n",
      "pf_290291065_186056_208025_66525.json 0.04206940520707286 0.22758077944779917\n",
      "pf_290291065_231109_201266_43815.json 0.09069548757676194 0.32216586351424914\n",
      "pf_290291065_277162_202372_46064.json 0.08788718506254345 0.28444879372437104\n",
      "pf_368151126_229312_160989_28545.json 0.12729951963796343 0.20613170362558525\n",
      "pf_368151126_242192_156208_31920.json 0.06579570349983292 0.3194224889968196\n",
      "pf_368151126_265168_155216_48390.json 0.07625022902672243 0.19594156908622917\n",
      "pf_368151126_278640_154672_56730.json 0.06150888761487699 0.09944850853406821\n",
      "pf_368151126_312688_149424_70050.json 0.1092105568734304 0.21050239929515274\n",
      "pf_368151126_329008_147296_78390.json 0.14239900116240606 0.27918113054635385\n",
      "pf_368151126_331184_145952_80700.json 0.06177165896821647 0.2059279979491747\n",
      "pf_368151126_341776_141616_82410.json 0.07641653311450497 0.7927105195834072\n",
      "pf_368151126_358048_132976_102720.json 0.10049716155015759 0.21068045684873452\n",
      "pf_368151283_168460_160430_24944.json 0.06242563935548661 0.2554322924323564\n",
      "pf_368151283_206558_156193_40634.json 0.08189163411970599 0.17989346688313224\n",
      "pf_368151283_251907_162040_38025.json 0.03565898319293124 0.15038614616027407\n",
      "pf_368151283_261412_160935_52034.json 0.016176149280214294 0.029247527263136154\n",
      "pf_368151283_271562_156850_47054.json 0.08791045929600057 0.746719665054195\n",
      "pf_368151283_370616_141207_99945.json 0.04252760399617851 0.06830508220484614\n",
      "pf_368151599_184128_192016_60300.json 0.11565683216796598 0.3358923057326907\n",
      "pf_368151599_211008_182544_76320.json 0.0740136769095233 0.16712246216769108\n",
      "pf_368151599_230144_178176_74820.json 0.032226199613432135 0.07367744114473036\n",
      "pf_368151599_238960_204624_104940.json 0.08731061396425957 0.08499356781675335\n",
      "pf_368151599_240768_176416_71790.json 0.10219475097063725 0.11296800122974876\n",
      "pf_368151599_250000_171872_68850.json 0.06467606545395978 0.16707259372127084\n",
      "pf_368151599_251552_173264_67890.json 0.05005624494257873 0.11123635120618813\n",
      "pf_368151599_266512_184208_86130.json 0.09304089577170266 0.14053469602572238\n",
      "pf_368151599_267808_148688_10680.json 0.10426444139208377 0.14697837050564228\n",
      "pf_368151599_268864_146688_34350.json 0.09850051262871413 0.2572675688775688\n",
      "pf_368151599_271408_149024_37410.json 0.07877258790907475 0.21762298487547704\n",
      "pf_368151599_272528_150896_41760.json 0.05850536685633881 0.21286175445204364\n",
      "pf_368151599_273968_149248_25530.json 0.054564060769389716 0.23418040807543475\n",
      "pf_368151599_279792_152848_57960.json 0.08445493733839307 0.20508094113002492\n",
      "pf_368151599_286992_154528_94560.json 0.07369167613598342 0.10203723642710755\n",
      "pf_368151599_291520_170144_42810.json 0.10863180727381923 0.34191569005574507\n",
      "pf_368151599_293072_160272_41130.json 0.07313102931823846 0.1401483163979234\n",
      "pf_368151599_303344_189424_7050.json 0.09364066360732799 0.31825226693087855\n",
      "pf_368151599_309344_184048_36240.json 0.05268412277376061 0.2635506873328827\n",
      "pf_369254559_126416_166592_59520.json 0.03884954736707236 0.2545865843531184\n",
      "pf_369254559_139440_163008_65220.json 0.07975542284780195 0.149252356587866\n",
      "pf_369254559_140112_166448_72750.json 0.0721776972769297 0.31742788637780583\n",
      "pf_369254559_158208_157024_95640.json 0.0692193961549162 0.21984116833653988\n",
      "pf_369254559_163584_161200_97650.json 0.04120365776651892 0.0842456181033443\n",
      "pf_369254559_170416_155584_82290.json 0.19059262354577777 0.22062207863110017\n",
      "pf_369254559_172160_155312_81150.json 0.022065436327669732 0.17784271552396555\n",
      "pf_369254559_172288_164512_100920.json 0.044588045066731155 0.17796744708044254\n",
      "pf_369254559_181424_152944_78210.json 0.061934688206223804 0.3036880415469736\n",
      "pf_369254559_204384_158976_75420.json 0.05988436685113895 0.3370415493729038\n",
      "pf_369254559_273040_153904_64830.json 0.05513250466389429 0.25075192438017413\n",
      "pf_369254559_314688_156368_45960.json 0.03599191800450875 0.11853898552103381\n",
      "pf_369254559_316864_155040_46980.json 0.052604075968940504 0.23825330341645465\n",
      "pf_369254559_51053_175694_64695.json 0.07931672662783872 0.3033905175627212\n",
      "pf_369254559_56719_178550_56835.json 0.01433070319568882 0.14955390807788618\n",
      "pf_369254559_74630_178314_70245.json 0.019851963672324578 0.17659275132979843\n",
      "pf_369254559_90423_171436_54405.json 0.059003369714481 0.11162663340395589\n",
      "pf_369312115_254048_151248_100200.json 0.09488821432450945 0.1960030355610005\n",
      "pf_369312115_264944_157568_41850.json 0.06585160469965384 0.1158780092562142\n",
      "pf_369312115_273504_157088_71850.json 0.0497697940912693 0.21707303733505054\n",
      "pf_369312115_279186_158914_58425.json 0.02384782343703358 0.09980588777714297\n",
      "pf_369312115_313072_153296_71130.json 0.06348308115950516 0.08442131491680481\n",
      "pf_369312115_343408_148560_90900.json 0.039270436384755164 0.04508107758134978\n",
      "pf_369312360_272784_158912_94770.json 0.0749899456395265 0.20665123772287328\n",
      "pf_369312360_274960_204496_23310.json 0.10463027990876281 0.2297809663557401\n",
      "pf_369312360_275232_158656_97230.json 0.0451385971362585 0.18057187621511578\n",
      "pf_369312360_278499_210945_40754.json 0.03226427748851587 0.14357128020766738\n",
      "pf_369312360_280768_156848_57990.json 0.13009365291512898 0.3226530101445214\n",
      "pf_369312360_293456_209808_63210.json 0.1130085560501024 0.4479380369669677\n",
      "pf_369312360_300240_169712_78420.json 0.05413739303151109 0.7316600824670237\n",
      "pf_369312360_304080_169680_81690.json 0.0956271660249211 0.8157449193128377\n",
      "pf_369312360_306400_197504_86910.json 0.12269738969538237 0.048660643103060584\n",
      "pf_369312360_307200_174496_90000.json 0.10150715280134567 0.12855429786205477\n",
      "pf_369312360_307328_198544_86910.json 0.08518741491805172 0.39310309951746963\n",
      "pf_369312360_314643_179194_92084.json 0.0823546217655274 0.484275438649219\n",
      "pf_369312699_198848_162624_35970.json 0.10313415226788744 0.18448324704462757\n",
      "pf_369312699_199952_164720_31470.json 0.024166447579798838 0.15188582317186386\n",
      "pf_369312699_210960_164704_30330.json 0.08749322472779247 0.2838403021611109\n",
      "pf_369312699_254144_156800_41310.json 0.11499438902056518 0.288869709888293\n",
      "pf_369312699_280896_154800_58080.json 0.0560690374827818 0.16895301564695553\n",
      "pf_369312699_349312_144784_83520.json 0.04665392273655353 0.31167686450162513\n",
      "pf_369312699_380800_135040_91530.json 0.06276823046977408 0.20154423448738643\n",
      "pf_636004167_187945_167660_26954.json 0.17527023947778964 0.37093749318591945\n",
      "pf_636004167_231012_166779_46664.json 0.06434143251754426 0.1724218549344536\n",
      "pf_636004167_240917_192073_68955.json 0.08095706977510328 0.12337201013511025\n",
      "pf_636004167_244326_211627_96764.json 0.04227917162389611 0.12788418615475783\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "for f in sorted(listdir('/Users/Ela_work/Documents/Neuroscience with Nate/neuroglancerproject/annotatedsynapses/')):\n",
    "    \n",
    "    if f[0]==\".\":\n",
    "        continue\n",
    "        \n",
    "    file_pathname = '/Users/Ela_work/Documents/Neuroscience with Nate/neuroglancerproject/annotatedsynapses/' + f\n",
    "    file_path = Path(file_pathname)\n",
    "    \n",
    "    \n",
    "    with open(Path(file_path), 'r') as myfile:\n",
    "        neuroglancer_data = json.load(myfile) \n",
    "        \n",
    "    nl_ = 'terminals'\n",
    "    neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "    df_points_terminal = pd.DataFrame([[v['point'][0]*16/1000,v['point'][1]*16/1000,v['point'][2]*30/1000] for v in neuroglancer_layer['annotations']] ,columns=['x','y','z'])\n",
    "    hull_terminal = ConvexHull(df_points_terminal)\n",
    "\n",
    "    nl_ = 'spines'\n",
    "    neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "    df_points_spine = pd.DataFrame([[v['point'][0]*16/1000,v['point'][1]*16/1000,v['point'][2]*30/1000] for v in neuroglancer_layer['annotations']] ,columns=['x','y','z'])\n",
    "    hull_spine = ConvexHull(df_points_spine)\n",
    "\n",
    "    print(f , hull_spine.volume , hull_terminal.volume)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc95dfc-c9ea-40b9-b0a3-78d4f5996566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuroglancer_path = Path('/Users/kperks/Library/CloudStorage/GoogleDrive-kperky@gmail.com/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/Nate_neuroglancer/pf_synapses/pf_282137001_213811_154407_44715.json')\n",
    "neuroglancer_path = Path('/Users/Ela_work/Documents/Neuroscience with Nate/neuroglancerproject/annotatedsynapses/pf_ 282137001_177240_175341_5265.json')\n",
    "\n",
    "\n",
    "#neuroglancer_path = Path('../annotatedsynapses/pf_ 282137001_177240_175341_5265.json')\n",
    "\n",
    "# neuroglancer_path = '/Users/kperks/Library/CloudStorage/GoogleDrive-kperky@gmail.com/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/Nate_neuroglancer/synaptic_labeling/finished'\n",
    "# filename = '387850816_type2spectrum_nbs.json'\n",
    "# neuroglancer_path = Path('/Users/kperks/Downloads/grc_483610898.json') # Path(neuroglancer_path) / filename # \n",
    "\n",
    "with open(Path(neuroglancer_path), 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    neuroglancer_data = json.load(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085bd45-c2b2-4b73-92a4-853a24b8d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_ = 'terminals'\n",
    "neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "df_points_terminal = pd.DataFrame([[v['point'][0]*16/1000,v['point'][1]*16/1000,v['point'][2]*30/1000] for v in neuroglancer_layer['annotations']] ,columns=['x','y','z'])\n",
    "hull_terminal = ConvexHull(df_points_terminal)\n",
    "\n",
    "nl_ = 'spines'\n",
    "neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "df_points_spine = pd.DataFrame([[v['point'][0]*16/1000,v['point'][1]*16/1000,v['point'][2]*30/1000] for v in neuroglancer_layer['annotations']] ,columns=['x','y','z'])\n",
    "hull_spine = ConvexHull(df_points_spine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d470115-4208-476d-b636-49ee3da65191",
   "metadata": {},
   "outputs": [],
   "source": [
    "hull_spine.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2626df-e301-40fe-a511-da37bed75929",
   "metadata": {},
   "outputs": [],
   "source": [
    "hull_terminal.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4da6b4-41e1-432b-b195-b879d08b2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f9f2c28-5ae4-4a01-b35a-e6d373cbbc50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipympl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m      2\u001b[0m ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m111\u001b[39m, projection\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m ax\u001b[38;5;241m.\u001b[39mscatter(df_points_terminal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], df_points_terminal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], df_points_terminal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m],color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/pyplot.py:934\u001b[0m, in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allnums) \u001b[38;5;241m==\u001b[39m max_open_warning \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    925\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_external(\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_open_warning\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m figures have been opened. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    927\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigures created through the pyplot interface \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using `matplotlib.pyplot.close()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[0;32m--> 934\u001b[0m manager \u001b[38;5;241m=\u001b[39m new_figure_manager(\n\u001b[1;32m    935\u001b[0m     num, figsize\u001b[38;5;241m=\u001b[39mfigsize, dpi\u001b[38;5;241m=\u001b[39mdpi,\n\u001b[1;32m    936\u001b[0m     facecolor\u001b[38;5;241m=\u001b[39mfacecolor, edgecolor\u001b[38;5;241m=\u001b[39medgecolor, frameon\u001b[38;5;241m=\u001b[39mframeon,\n\u001b[1;32m    937\u001b[0m     FigureClass\u001b[38;5;241m=\u001b[39mFigureClass, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    938\u001b[0m fig \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fig_label:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/pyplot.py:464\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_figure_manager\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new figure manager instance.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m     _warn_if_gui_out_of_main_thread()\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mnew_figure_manager(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/pyplot.py:441\u001b[0m, in \u001b[0;36m_warn_if_gui_out_of_main_thread\u001b[0;34m()\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_warn_if_gui_out_of_main_thread\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    440\u001b[0m     warn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     canvas_class \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mtype\u001b[39m[FigureCanvasBase], _get_backend_mod()\u001b[38;5;241m.\u001b[39mFigureCanvas)\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m canvas_class\u001b[38;5;241m.\u001b[39mrequired_interactive_framework:\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(threading, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_native_id\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;66;03m# This compares native thread ids because even if Python-level\u001b[39;00m\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;66;03m# Thread objects match, the underlying OS thread (which is what\u001b[39;00m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# really matters) may be different on Python implementations with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# green threads.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/pyplot.py:280\u001b[0m, in \u001b[0;36m_get_backend_mod\u001b[0;34m()\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03mEnsure that a backend is selected and return it.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03mThis is currently private, but may be made public in the future.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _backend_mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# Use rcParams._get(\"backend\") to avoid going through the fallback\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# logic (which will (re)import pyplot and then call switch_backend if\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# we need to resolve the auto sentinel)\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     switch_backend(rcParams\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mtype\u001b[39m[matplotlib\u001b[38;5;241m.\u001b[39mbackend_bases\u001b[38;5;241m.\u001b[39m_Backend], _backend_mod)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/pyplot.py:342\u001b[0m, in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# have to escape the switch on access logic\u001b[39;00m\n\u001b[1;32m    340\u001b[0m old_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(rcParams, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 342\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(cbook\u001b[38;5;241m.\u001b[39m_backend_module_name(newbackend))\n\u001b[1;32m    343\u001b[0m canvas_class \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mFigureCanvas\n\u001b[1;32m    345\u001b[0m required_framework \u001b[38;5;241m=\u001b[39m canvas_class\u001b[38;5;241m.\u001b[39mrequired_interactive_framework\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1310\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1324\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipympl'"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(df_points_terminal['x'], df_points_terminal['y'], df_points_terminal['z'],color='black')\n",
    "for i in hull_terminal.simplices:\n",
    "    plt.plot(hull_terminal.points[i,0], hull_terminal.points[i,1], hull_terminal.points[i,2], 'r-')\n",
    "\n",
    "ax.scatter(df_points_spine['x'], df_points_spine['y'], df_points_spine['z'],color='black')\n",
    "for i in hull_spine.simplices:\n",
    "    plt.plot(hull_spine.points[i,0], hull_spine.points[i,1], hull_spine.points[i,2], 'g-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f441cc23-8474-4c6f-87f8-ac2531178f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c6a79-6903-4341-b7da-a902bfc81a6f",
   "metadata": {},
   "source": [
    "## eCREST from json segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e3568-6113-413b-b3be-054a3256c602",
   "metadata": {},
   "source": [
    "### neuroglancer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140c84b-d9f6-43ec-b178-c72dcf40deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroglancer_path = Path(settings_dict['save_dir']) / 'Nate_neuroglancer/synaptic_labeling/finished'\n",
    "# neuroglancer_path = '/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/Nate_neuroglancer/synaptic_labeling/finished'\n",
    "filename = '216129202_type2spectrum_nbs.json'\n",
    "neuroglancer_path = Path(neuroglancer_path) / filename # Path('/Users/kperks/Downloads/grc_483610898.json') # \n",
    "\n",
    "with open(Path(neuroglancer_path), 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    neuroglancer_data = json.load(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3568553c-bbb7-4ad2-9ad7-c4a62d611784",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_layer = next((item for item in neuroglancer_data['layers'] if item[\"source\"] == 'brainmaps://10393113184:ell:roi450um_seg32fb16fb_220930'), None)\n",
    "base_segment_list_ng = set(segmentation_layer['segments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975f45a-2ee6-4481-8ea5-38ec5de40961",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_segment_list_ng = list(set([bs for bs in base_segment_list_ng if '!' not in bs]))# -set(['283547027']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d004dc-0fca-454f-a3b9-01be695e3275",
   "metadata": {},
   "source": [
    "### initiate cell if not already a crest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba90c2c-1a39-48fd-af31-7c74f51f03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = filename.split('_')[0]\n",
    "crest = ecrest(settings_dict, segment_id = segment_id, segment_list = base_segment_list_ng, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23160c0-039a-4fee-a9c2-33f92ba1ad13",
   "metadata": {},
   "source": [
    "### compare base segments with ecrest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf6e8a-5e26-49b1-9294-415d244ece17",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = Path(settings_dict['save_dir']) #/ 'todo_presynaptic/mg1_299496636' #/ 'kp/pfs'#/ 'volume-subsample-all/in_progress'  ## specify the directory path\n",
    "cell_filepaths = get_cell_filepaths(directory_path) # gets filepaths for all cells in a directory\n",
    "# cell_filepaths = cell_filepaths_mainnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c603b1-0341-4886-b265-ca5efbcaf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = filename.split('_')[0]#'483610898'#\n",
    "# crest = ecrest(settings_dict, segment_id = segment_id, segment_list = base_segment_list_ng, launch_viewer=True)\n",
    "\n",
    "crest = ecrest(settings_dict, filepath= cell_filepaths[cell_id], launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d34ede-0a43-400c-b690-ebf9f596330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(base_segment_list_ng) - set([a for _,b in crest.cell_data['base_segments'].items() for a in b])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55b034-79e3-4889-8541-b0e6bb5dd78c",
   "metadata": {},
   "source": [
    "### Add points from annotation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884048b7-66b3-49f9-9b3f-e6f5c1febb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([item['name'] for item in neuroglancer_data['layers'] if item['type']=='annotation'])-set(['Base Segment Merger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a43ecc-17bc-45d2-a257-36ac9b313c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Currently only works for annotation layers that you know contain only point annotations!!!\n",
    "'''\n",
    "neuroglancer_layer_name = ['pre-synaptic','post-synaptic']#, 'natural end','exit volume','uncertain']# set([item['name'] for item in neuroglancer_data['layers'] if item['type']=='annotation'])-set(['Base Segment Merger'])\n",
    "crest_layer_name = neuroglancer_layer_name #['post-synaptic','pre-synaptic']#,\n",
    "\n",
    "for nl_, cl_ in zip(neuroglancer_layer_name, crest_layer_name):\n",
    "    neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "    \n",
    "    if neuroglancer_layer != None:\n",
    "        if cl_ in crest.point_types:\n",
    "            \n",
    "            this_type_points = crest.cell_data['end_points'][cl_]\n",
    "            for v in neuroglancer_layer['annotations']: \n",
    "\n",
    "                co_ords = [float(x) for x in v['point']]\n",
    "                co_ords_and_id = ([co_ords[x]*crest.vx_sizes['em'][x] for x in range(3)])\n",
    "\n",
    "                if 'segments' in v.keys(): #v['segments'] != None:\n",
    "                    if len(v['segments'][0]) > 0:\n",
    "                        co_ords_and_id.append(str(v['segments'][0][0]))\n",
    "\n",
    "                this_type_points.append((co_ords_and_id,'annotatePoint'))\n",
    "            \n",
    "            # remove duplicates with annotations already existing\n",
    "            # Convert inner lists to tuples\n",
    "            this_type_points = crest.cell_data['end_points'][cl_] + this_type_points\n",
    "\n",
    "            this_type_points = [(tuple(inner_list), label) for inner_list, label in this_type_points]\n",
    "\n",
    "            # Use a set to track unique elements based on the converted tuples\n",
    "            unique_end_points_set = set(this_type_points)\n",
    "\n",
    "            # Convert inner tuples back to lists for the final result\n",
    "            this_type_points = [(list(inner_tuple), label) for inner_tuple, label in unique_end_points_set]\n",
    "\n",
    "\n",
    "            crest.cell_data['end_points'][cl_] =  this_type_points\n",
    "        else: \n",
    "            msg = f\"CREST layer name - {cl_} - incorrect for cell {crest.cell_data['metadata']['main_seg']['base']} in conversion_json\"\n",
    "            print(msg)\n",
    "\n",
    "    else:\n",
    "        msg = f\"no layer by the name - {nl_} - in neuroglancer json for cell {crest.cell_data['metadata']['main_seg']['base']}\"\n",
    "        print(msg)\n",
    "        \n",
    "crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f6325-79a3-4d5d-80a2-01e1d7a63e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crest.cell_data['end_points']= crest_ann.cell_data['end_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9ae27-0f2d-40ed-9250-09f06f4ff8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a710b-4864-401b-9058-a60cf3b04a2c",
   "metadata": {},
   "source": [
    "### define type and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4a1a1-d6df-4d63-a453-b35792b387cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.save_cell_graph()#directory_path = cell_filepaths[cell_id].parent, file_name = cell_filepaths[cell_id].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273fd827-f4a4-4891-b736-acd29177004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = 'sg1' # Assign the cell type then run the code cell\n",
    "\n",
    "crest.define_ctype(cell_type,\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c8b6c-a9d1-4f78-be5c-2ede5d336b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE YOUR WORK!\n",
    "\n",
    "crest.save_cell_graph() # Default location is Path(settings_dict['save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a9224-57b2-41f7-a63f-4716608bddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crest.add_endpoint_annotation_layers(['soma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc33c979-22e0-406a-8e85-3897744a5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.cell_data['end_points']['uncertain'] = [r for r in crest.cell_data['end_points']['uncertain'] if r[1] < (11100*16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e8695-9d49-48ec-8464-a447f72d4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c5124-2587-4fbd-aebd-c126ac5259ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_segments_net = crest.get_base_segments_dict(Path(settings_dict['save_dir']))\n",
    "base_segments_todo = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_presynaptic/lf_393325331')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd284024-9b81-4481-8bde-1ad7fc1387f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('overlap in main network:'); df = crest.check_duplicates(base_segments_net); display(df)\n",
    "print('overlap in todo folder:'); df = crest.check_duplicates(base_segments_todo); display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bffbd-db9f-4427-82b9-b817e50a8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = 'sgx1' # Assign the cell type then run the code cell\n",
    "\n",
    "crest.define_ctype(cell_type,\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340fa4b-cdd6-4568-b297-d1f14fd9b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE YOUR WORK!\n",
    "\n",
    "crest.save_cell_graph() # Default location is Path(settings_dict['save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c1dd6-c66c-4a11-9e30-5a296345b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_filepaths[cell_id].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346aa47b-1ca1-4908-9f3c-f5348a7f3de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.get_ctype('manual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca480f8-1418-4e66-8361-af703999e334",
   "metadata": {},
   "source": [
    "### add segments if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d16ca4-d86d-4658-a6ba-48636b1864df",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ids_added = set()\n",
    "for base_seg in set(base_segment_list_ng) - set([a for _,b in crest.cell_data['base_segments'].items() for a in b]):\n",
    "    \n",
    "    if (base_ids_added&set(base_seg)==set()) & (base_seg != crest.cell_data['metadata']['main_seg']['base']): \n",
    "        \n",
    "        displayed_segs = crest.assert_segs_in_sync(return_segs=True)\n",
    "        if base_seg in displayed_segs:\n",
    "            # print(f'{base_seg} already in cell, continueing')\n",
    "            continue\n",
    "\n",
    "        # print(i,base_seg)\n",
    "        agglo_seg = crest.get_agglo_seg_of_base_seg(base_seg)\n",
    "\n",
    "        constituent_base_ids = crest.get_base_segs_of_agglo_seg(agglo_seg)        \n",
    "        current_segs = crest.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        num_base_segs_this_agglo_seg = len(constituent_base_ids)\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in current_segs]\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in crest.cell_data['removed_base_segs']]\n",
    "        num_base_segs_not_already_included = len(constituent_base_ids)\n",
    "        \n",
    "        if len(constituent_base_ids) > crest.max_num_base_added:\n",
    "            base_ids = [base_seg]\n",
    "            # crest.large_agglo_segs.add(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {crest.max_num_base_added}')\n",
    "            # print(f'{base_seg} part of an agglo seg {agglo_seg} that is too large to add, so just adding the one segment')\n",
    "        else:\n",
    "            base_ids = constituent_base_ids\n",
    "\n",
    "        if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "            if not base_seg in base_ids:\n",
    "                base_ids.append(base_seg)\n",
    "        print(base_ids)\n",
    "        crest.update_base_locations(base_ids)\n",
    "        crest.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "        if len(base_ids) > 1:\n",
    "            edges = crest.get_edges_from_agglo_seg(agglo_seg)\n",
    "            edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "            crest.pr_graph.add_edges(edges)\n",
    "\n",
    "        join_msg = crest.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "        \n",
    "\n",
    "        # Update lists of base segments and displayed segs:\n",
    "        crest.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "        with crest.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in base_ids:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = '#d2b48c'\n",
    "                s.layers['base_segs'].segments.add(int(bs))\n",
    "                \n",
    "        base_ids_added.update(base_ids)\n",
    "\n",
    "\n",
    "        crest.update_displayed_segs() \n",
    "        crest.assert_segs_in_sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff17aff-a561-4adc-bf88-e7d5a5b5188b",
   "metadata": {},
   "source": [
    "## Molecular layer fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f24a22-5980-4c98-95a3-0cf63cfeaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit \n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90154c-f846-49d0-be79-dd692551a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mathematical function for curve fitting \n",
    "def func(xy, a, b, c, d, e, f, g, h):  # #h):#\n",
    "    x, y = xy \n",
    "    return a + b*x + c*y + d*x**2 + e*y**2 + f*x**3 + g*y**3 + h*x*y # + h*x*y #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80cb3d-85b5-40d5-809e-9243dff5bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(settings_dict['save_dir']).parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a10d3b-681c-4e74-b34f-3d78150564e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroglancer_path = Path(settings_dict['save_dir']).parent.parent / 'Krista/blender/soma_locations/layer-molecular_annotation.json'\n",
    "voxel_sizes = [16,16,30]\n",
    "nl_ = 'molecular'\n",
    "\n",
    "with open(Path(neuroglancer_path), 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    neuroglancer_data = json.load(myfile)\n",
    "    \n",
    "neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "vertices = [[p['point'][i]*voxel_sizes[i] for i in range(3)] for p in neuroglancer_layer['annotations']]\n",
    "\n",
    "x_pts = [p[0] for p in vertices]\n",
    "y_pts = [p[1] for p in vertices]\n",
    "z_pts = [p[2] for p in vertices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370c66b-ea3b-4b0a-8080-85a0237f0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform curve fitting \n",
    "popt, pcov = curve_fit(func, (x_pts, z_pts), y_pts) \n",
    "  \n",
    "# Print optimized parameters \n",
    "print(popt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e8c97-3820-40b8-b451-4c1c87015c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3D plot of the data points and the fitted curve \n",
    "fig = plt.figure(figsize=(10,10)) \n",
    "ax = fig.add_subplot(111, projection='3d') \n",
    "ax.scatter(x_pts, z_pts, y_pts, color='blue') \n",
    "x_range = np.linspace(np.min(x_pts), np.max(x_pts), 100) \n",
    "z_range = np.linspace(np.min(z_pts), np.max(z_pts), 100) \n",
    "X, Z = np.meshgrid(x_range, z_range) \n",
    "Y = func((X, Z), *popt) \n",
    "ax.plot_surface(X, Z, Y, color='red', alpha=0.5) \n",
    "ax.set_xlabel('X') \n",
    "ax.set_ylabel('Z') \n",
    "ax.set_zlabel('Y') \n",
    "# plt.show()\n",
    "ax.set_aspect('equal') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7b295-093c-47bb-ac2a-41eb838ad515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d392e9b-88bd-4620-b6c7-82dcd242b342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
