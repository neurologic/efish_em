


from pathlib import Path
import json
import pandas as pd
import numpy as np
import time
from tqdm import tqdm
import trimesh
import cloudvolume as cv
from google.cloud import bigquery
from cloudvolume import CloudVolume 
import os
from sqlite3 import connect as sqlite3_connect
from sqlite3 import DatabaseError
from cloudvolume.exceptions import EmptyFileException, MeshDecodeError
# from google.oauth2 import service_account


import sys
sys.path.append('/Users/kperks/Documents/ell-connectome/efish_em/efish_em')


# from eCREST_cli_beta import ecrest, import_settings
# from eCREST_cli import ecrest
import AnalysisCode as efish 


'''
conda install conda-forge::google-cloud-sdk

Then, launch jupyter lab 

In a code cell, run bash command <!gcloud auth login > (https://cloud.google.com/sdk/gcloud/reference/auth/login)
    a browser tab should open up

RESULT:
You are now logged in as [kperky@gmail.com].
Your current project is [lcht-goog-connectomics].  You can change this setting by running:
  $ gcloud config set project PROJECT_ID
'''
!gcloud auth login 


import sys
sys.path.append('/Users/kperks/Documents/ell-connectome/efish_em/efish_em')


# from eCREST_cli_beta import ecrest, import_settings
from eCREST_cli import ecrest, import_settings, get_cell_filepaths


path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'
settings_dict = import_settings(path_to_settings_json)

vx_sizes = [16,16,30]

db_cursors = sqlite3_connect(settings_dict['db_path'], check_same_thread=False).cursor()

a = ', '.join(['base_address'])

db_cursors.execute(f'''SELECT {a} FROM addresses_table LIMIT 1''')

[base_seg] = db_cursors.fetchall()[0]

mesh_seg = 'precomputed://gs+ngauth+https://ngauth-goog.appspot.com/fish-ell/roi450um_seg32fb16fb_220930'





efish_cloudvolume = cv.CloudVolume('gs://fish-ell/roi450um_seg32fb16fb_220930', progress=False)
# efish_cloudvolume = cv.CloudVolume('precomputed://http://localhost:8001', progress=False)



# efish_img = cv.CloudVolume('gs://fish-ell/roi450um_xyz', progress=False)





# dirpath = Path(settings_dict['save_dir'])
dirpath = Path('/Users/kperks/Documents/sawtell_lab/EM_data/reconstructions_published')

nodefiles = get_cell_filepaths(dirpath)


# df_type = pd.read_csv(dirpath / 'metadata/df_type_auto_typed.csv')
df_type= pd.read_csv(dirpath.parent / 'data_processed_published/df_type_auto_typed.csv')





# resort existing and figure out which needed





savepath = Path('/Users/kperks/Library/CloudStorage/GoogleDrive-sawtelllab@gmail.com/My Drive/ELL_connectome/ms/revision_stage/blender/MG_convergence/OFF')


savepath


all_cells =  [387382792, 128536704, 386300356, 303877666, 129619070, 387338914,
       386117124, 472284925, 644824766,  40448913, 300316308, 472051969,
       299249397, 301339154, 300503092, 302544942, 472115344, 129512755]


howmuch = 'list' #'single' #'all'  #
save_str_detail = 'notaxon'
dtype = 'axon'
dtype_list = ['unknown','basal dendrite','apical dendrite','multiple']
reduction_ratio = 0.2

scale_factor = 100000
yaxis_replace_scale = 32768*16/scale_factor
# zaxis_replace_scale = 3534*30/scale_factor
refpt = [0,0,0]

# with tqdm(total=len(all_cells)) as pbar:        
for focal_cell_id in all_cells:
    # pbar.update(1)
    
    dirpath = Path(settings_dict['save_dir'])
    focal_cell_fname = nodefiles[str(focal_cell_id)]#

    cell_data = efish.load_ecrest_celldata(nodefiles[str(focal_cell_id)])
    # cell = ecrest(settings_dict,filepath = dirpath / focal_cell_fname, launch_viewer=False)
    ctype = df_type[df_type['id']==focal_cell_id]['cell_type'].values[0]#cell.get_ctype('manual')

    if howmuch == 'list':
        mesh_ids = [bs for dtype in dtype_list for bs in cell_data['base_segments'][dtype]] # for subset list of cell structures
    if howmuch == 'single':
        mesh_ids = [bs for bs in cell_data['base_segments'][dtype]] # if only need segments from one cell structure #
    if howmuch == 'all':
        mesh_ids = [bs for dtype in cell_data['base_segments'].keys() for bs in cell_data['base_segments'][dtype]] #if need all segments

    # grab the mesh for more than one object
    # Initialize an empty Trimesh object
    fused_mesh = trimesh.Trimesh()
    with tqdm(total=len(mesh_ids)) as pbar:        
        for id in mesh_ids:
            pbar.update(1)
            try:
                mesh = efish_cloudvolume.mesh.get(int(id))
                vertices = list(mesh.values())[0].vertices
                vertices = vertices/scale_factor
                vertices = [[v[0]-refpt[0],v[1]-refpt[1],v[2]-refpt[2]] for i,v in enumerate(vertices)]
                vertices = [[v[0],yaxis_replace_scale-v[1],v[2]] for v in vertices]
                faces = list(mesh.values())[0].faces
                trimesh_mesh = trimesh.Trimesh(vertices=vertices, faces=faces,process=True)
                
                # downsample the fused mesh before joining to the fused_mesh and exporting as a .obj for blender
                simplified_mesh = trimesh_mesh.simplify_quadric_decimation(face_count=len(trimesh_mesh.vertices) * reduction_ratio)
                fused_mesh = trimesh.util.concatenate([fused_mesh, simplified_mesh])

            except MeshDecodeError as e: 
                print(f"An unexpected error occurred on segment{id}: {e}")
                continue

            except ValueError as e:
                print(f"An unexpected error occurred on segment{id}: {e}")
                continue
    
        # prompt: downsample the fused mesh before exporting as a .obj for blender
        # reduction_ratio = 0.2
        # simplified_mesh = fused_mesh.simplify_quadric_decimation(face_count=len(fused_mesh.vertices) * reduction_ratio)

    fused_mesh.export(savepath / f'{ctype}_{focal_cell_id}_{save_str_detail}.obj');





vol = CloudVolume('precomputed://http://localhost:1337')


segIDs_all = vol.unique(bbox=vol.bounds) - set([0]) # get all segment IDs in volume and remove segment ID 0, which is background


savepath = Path('/Users/kperks/Library/CloudStorage/GoogleDrive-sawtelllab@gmail.com/My Drive/ELL_connectome/ms/figures_final/blender/obj/Fig1/OUTPUT_in-sub-vol')

for s in list(segIDs_all):
        
    mesh= vol.mesh.get(int(s))
    
    # reduction_ratio = 0.2
    
    scale_factor = 100000
    yaxis_replace_scale = 32768*16/scale_factor
    # zaxis_replace_scale = 3534*30/scale_factor
    refpt = [0,0,0]
    
    vertices = mesh.vertices
    vertices = vertices/scale_factor
    vertices = [[v[0]-refpt[0],v[1]-refpt[1],v[2]-refpt[2]] for i,v in enumerate(vertices)]
    vertices = [[v[0],yaxis_replace_scale-v[1],v[2]] for v in vertices]
    faces = mesh.faces
    trimesh_mesh = trimesh.Trimesh(vertices=vertices, faces=faces,process=True)

    # downsample the fused mesh before joining to the fused_mesh and exporting as a .obj for blender
    # simplified_mesh = trimesh_mesh.simplify_quadric_decimation(face_count=len(trimesh_mesh.vertices) * reduction_ratio)
    
    
    trimesh_mesh.export(savepath / f'{s}.obj')



